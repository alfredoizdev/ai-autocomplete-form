{
  "best_global_step": 500,
  "best_metric": 10.94511890411377,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 6630,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02262443438914027,
      "grad_norm": 245.67630004882812,
      "learning_rate": 0.000294,
      "loss": 7.4688,
      "step": 50
    },
    {
      "epoch": 0.04524886877828054,
      "grad_norm": 732.97119140625,
      "learning_rate": 0.0002977659574468085,
      "loss": 7.1876,
      "step": 100
    },
    {
      "epoch": 0.06787330316742081,
      "grad_norm": 93.81067657470703,
      "learning_rate": 0.0002954863221884498,
      "loss": 11.6497,
      "step": 150
    },
    {
      "epoch": 0.09049773755656108,
      "grad_norm": 227.9821319580078,
      "learning_rate": 0.00029320668693009116,
      "loss": 11.3275,
      "step": 200
    },
    {
      "epoch": 0.11312217194570136,
      "grad_norm": 209.642822265625,
      "learning_rate": 0.0002909270516717325,
      "loss": 9.676,
      "step": 250
    },
    {
      "epoch": 0.13574660633484162,
      "grad_norm": 248.77206420898438,
      "learning_rate": 0.00028864741641337384,
      "loss": 10.0208,
      "step": 300
    },
    {
      "epoch": 0.1583710407239819,
      "grad_norm": 66.68116760253906,
      "learning_rate": 0.0002863677811550152,
      "loss": 8.6539,
      "step": 350
    },
    {
      "epoch": 0.18099547511312217,
      "grad_norm": 460.8623046875,
      "learning_rate": 0.0002840881458966565,
      "loss": 9.5048,
      "step": 400
    },
    {
      "epoch": 0.20361990950226244,
      "grad_norm": 226.59608459472656,
      "learning_rate": 0.00028180851063829785,
      "loss": 11.0892,
      "step": 450
    },
    {
      "epoch": 0.22624434389140272,
      "grad_norm": 360.4206237792969,
      "learning_rate": 0.0002795288753799392,
      "loss": 11.3742,
      "step": 500
    },
    {
      "epoch": 0.22624434389140272,
      "eval_loss": 10.94511890411377,
      "eval_runtime": 16.2655,
      "eval_samples_per_second": 241.554,
      "eval_steps_per_second": 30.248,
      "step": 500
    },
    {
      "epoch": 0.248868778280543,
      "grad_norm": 7867.9287109375,
      "learning_rate": 0.0002772492401215805,
      "loss": 14.0583,
      "step": 550
    },
    {
      "epoch": 0.27149321266968324,
      "grad_norm": 3816.457275390625,
      "learning_rate": 0.00027496960486322186,
      "loss": 27.5085,
      "step": 600
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 3231.7080078125,
      "learning_rate": 0.0002726899696048632,
      "loss": 32.2731,
      "step": 650
    },
    {
      "epoch": 0.3167420814479638,
      "grad_norm": 2053.893310546875,
      "learning_rate": 0.00027041033434650454,
      "loss": 32.6794,
      "step": 700
    },
    {
      "epoch": 0.3393665158371041,
      "grad_norm": 1854.6168212890625,
      "learning_rate": 0.0002681306990881459,
      "loss": 33.1468,
      "step": 750
    },
    {
      "epoch": 0.36199095022624433,
      "grad_norm": 1972.70703125,
      "learning_rate": 0.0002658510638297872,
      "loss": 33.1206,
      "step": 800
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1599.8082275390625,
      "learning_rate": 0.00026357142857142855,
      "loss": 33.1759,
      "step": 850
    },
    {
      "epoch": 0.4072398190045249,
      "grad_norm": 2821.474853515625,
      "learning_rate": 0.0002612917933130699,
      "loss": 32.9813,
      "step": 900
    },
    {
      "epoch": 0.4298642533936652,
      "grad_norm": 2103.5322265625,
      "learning_rate": 0.0002590121580547112,
      "loss": 31.8786,
      "step": 950
    },
    {
      "epoch": 0.45248868778280543,
      "grad_norm": 2291.745361328125,
      "learning_rate": 0.00025673252279635256,
      "loss": 31.5912,
      "step": 1000
    },
    {
      "epoch": 0.45248868778280543,
      "eval_loss": 28.694955825805664,
      "eval_runtime": 15.317,
      "eval_samples_per_second": 256.513,
      "eval_steps_per_second": 32.121,
      "step": 1000
    },
    {
      "epoch": 0.4751131221719457,
      "grad_norm": 3336.257080078125,
      "learning_rate": 0.0002544528875379939,
      "loss": 28.7914,
      "step": 1050
    },
    {
      "epoch": 0.497737556561086,
      "grad_norm": 135296.46875,
      "learning_rate": 0.00025217325227963524,
      "loss": 28.063,
      "step": 1100
    },
    {
      "epoch": 0.5203619909502263,
      "grad_norm": 2455.054443359375,
      "learning_rate": 0.0002498936170212766,
      "loss": 26.8572,
      "step": 1150
    },
    {
      "epoch": 0.5429864253393665,
      "grad_norm": 2859.03076171875,
      "learning_rate": 0.0002476139817629179,
      "loss": 25.7103,
      "step": 1200
    },
    {
      "epoch": 0.5656108597285068,
      "grad_norm": 2712.672607421875,
      "learning_rate": 0.00024533434650455925,
      "loss": 24.5041,
      "step": 1250
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2609.429443359375,
      "learning_rate": 0.0002430547112462006,
      "loss": 23.6657,
      "step": 1300
    },
    {
      "epoch": 0.6108597285067874,
      "grad_norm": 3595.8017578125,
      "learning_rate": 0.00024077507598784193,
      "loss": 23.764,
      "step": 1350
    },
    {
      "epoch": 0.6334841628959276,
      "grad_norm": 3580.08935546875,
      "learning_rate": 0.00023849544072948326,
      "loss": 24.4786,
      "step": 1400
    },
    {
      "epoch": 0.6561085972850679,
      "grad_norm": 2850.406982421875,
      "learning_rate": 0.0002362158054711246,
      "loss": 24.6255,
      "step": 1450
    },
    {
      "epoch": 0.6787330316742082,
      "grad_norm": 253204.6875,
      "learning_rate": 0.00023393617021276594,
      "loss": 23.8975,
      "step": 1500
    },
    {
      "epoch": 0.6787330316742082,
      "eval_loss": 23.978788375854492,
      "eval_runtime": 16.1537,
      "eval_samples_per_second": 243.226,
      "eval_steps_per_second": 30.457,
      "step": 1500
    },
    {
      "epoch": 0.7013574660633484,
      "grad_norm": 21451.8984375,
      "learning_rate": 0.00023165653495440725,
      "loss": 25.804,
      "step": 1550
    },
    {
      "epoch": 0.7239819004524887,
      "grad_norm": 14165.681640625,
      "learning_rate": 0.0002293768996960486,
      "loss": 26.8192,
      "step": 1600
    },
    {
      "epoch": 0.746606334841629,
      "grad_norm": 10640.458984375,
      "learning_rate": 0.00022709726443768995,
      "loss": 25.8111,
      "step": 1650
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 14031.458984375,
      "learning_rate": 0.0002248176291793313,
      "loss": 26.2866,
      "step": 1700
    },
    {
      "epoch": 0.7918552036199095,
      "grad_norm": 15612.283203125,
      "learning_rate": 0.00022253799392097263,
      "loss": 26.2238,
      "step": 1750
    },
    {
      "epoch": 0.8144796380090498,
      "grad_norm": 8646.9814453125,
      "learning_rate": 0.00022025835866261396,
      "loss": 25.6758,
      "step": 1800
    },
    {
      "epoch": 0.8371040723981901,
      "grad_norm": 12154.640625,
      "learning_rate": 0.0002179787234042553,
      "loss": 25.5278,
      "step": 1850
    },
    {
      "epoch": 0.8597285067873304,
      "grad_norm": 19613.658203125,
      "learning_rate": 0.00021569908814589664,
      "loss": 25.5375,
      "step": 1900
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 11714.4765625,
      "learning_rate": 0.000213419452887538,
      "loss": 25.9865,
      "step": 1950
    },
    {
      "epoch": 0.9049773755656109,
      "grad_norm": 17331.455078125,
      "learning_rate": 0.00021113981762917929,
      "loss": 25.8091,
      "step": 2000
    },
    {
      "epoch": 0.9049773755656109,
      "eval_loss": 26.63210678100586,
      "eval_runtime": 15.2567,
      "eval_samples_per_second": 257.526,
      "eval_steps_per_second": 32.248,
      "step": 2000
    },
    {
      "epoch": 0.9276018099547512,
      "grad_norm": 19601.541015625,
      "learning_rate": 0.00020886018237082065,
      "loss": 26.642,
      "step": 2050
    },
    {
      "epoch": 0.9502262443438914,
      "grad_norm": 13669.7138671875,
      "learning_rate": 0.000206580547112462,
      "loss": 25.9498,
      "step": 2100
    },
    {
      "epoch": 0.9728506787330317,
      "grad_norm": 15616.9853515625,
      "learning_rate": 0.00020430091185410333,
      "loss": 26.0879,
      "step": 2150
    },
    {
      "epoch": 0.995475113122172,
      "grad_norm": 14610.7919921875,
      "learning_rate": 0.00020202127659574466,
      "loss": 26.228,
      "step": 2200
    },
    {
      "epoch": 1.0180995475113122,
      "grad_norm": 14751.0224609375,
      "learning_rate": 0.000199741641337386,
      "loss": 25.1988,
      "step": 2250
    },
    {
      "epoch": 1.0407239819004526,
      "grad_norm": 18903.611328125,
      "learning_rate": 0.00019746200607902734,
      "loss": 26.9424,
      "step": 2300
    },
    {
      "epoch": 1.0633484162895928,
      "grad_norm": 15148.12890625,
      "learning_rate": 0.00019518237082066868,
      "loss": 26.678,
      "step": 2350
    },
    {
      "epoch": 1.085972850678733,
      "grad_norm": 13884.2451171875,
      "learning_rate": 0.00019290273556231004,
      "loss": 26.3561,
      "step": 2400
    },
    {
      "epoch": 1.1085972850678734,
      "grad_norm": 14423.845703125,
      "learning_rate": 0.00019062310030395135,
      "loss": 26.7947,
      "step": 2450
    },
    {
      "epoch": 1.1312217194570136,
      "grad_norm": 19363.873046875,
      "learning_rate": 0.0001883434650455927,
      "loss": 25.3999,
      "step": 2500
    },
    {
      "epoch": 1.1312217194570136,
      "eval_loss": 26.55757713317871,
      "eval_runtime": 15.2488,
      "eval_samples_per_second": 257.659,
      "eval_steps_per_second": 32.265,
      "step": 2500
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 44809.90234375,
      "learning_rate": 0.00018606382978723403,
      "loss": 25.889,
      "step": 2550
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 17182.92578125,
      "learning_rate": 0.00018378419452887536,
      "loss": 25.7202,
      "step": 2600
    },
    {
      "epoch": 1.1990950226244343,
      "grad_norm": 19301.1015625,
      "learning_rate": 0.0001815045592705167,
      "loss": 25.3273,
      "step": 2650
    },
    {
      "epoch": 1.2217194570135748,
      "grad_norm": 11811.4990234375,
      "learning_rate": 0.00017922492401215804,
      "loss": 27.159,
      "step": 2700
    },
    {
      "epoch": 1.244343891402715,
      "grad_norm": 12336.6884765625,
      "learning_rate": 0.00017694528875379938,
      "loss": 26.0489,
      "step": 2750
    },
    {
      "epoch": 1.2669683257918551,
      "grad_norm": 13795.244140625,
      "learning_rate": 0.00017466565349544074,
      "loss": 25.8913,
      "step": 2800
    },
    {
      "epoch": 1.2895927601809956,
      "grad_norm": 20558.927734375,
      "learning_rate": 0.00017238601823708202,
      "loss": 26.684,
      "step": 2850
    },
    {
      "epoch": 1.3122171945701357,
      "grad_norm": 23968.98046875,
      "learning_rate": 0.0001701063829787234,
      "loss": 26.0355,
      "step": 2900
    },
    {
      "epoch": 1.334841628959276,
      "grad_norm": 18545.306640625,
      "learning_rate": 0.00016782674772036473,
      "loss": 26.2523,
      "step": 2950
    },
    {
      "epoch": 1.3574660633484164,
      "grad_norm": 24297.90625,
      "learning_rate": 0.00016554711246200606,
      "loss": 26.8881,
      "step": 3000
    },
    {
      "epoch": 1.3574660633484164,
      "eval_loss": 26.82853889465332,
      "eval_runtime": 15.3212,
      "eval_samples_per_second": 256.442,
      "eval_steps_per_second": 32.112,
      "step": 3000
    },
    {
      "epoch": 1.3800904977375565,
      "grad_norm": 16911.8671875,
      "learning_rate": 0.0001632674772036474,
      "loss": 26.2736,
      "step": 3050
    },
    {
      "epoch": 1.4027149321266967,
      "grad_norm": 13219.197265625,
      "learning_rate": 0.00016098784194528874,
      "loss": 26.2093,
      "step": 3100
    },
    {
      "epoch": 1.4253393665158371,
      "grad_norm": 31602572.0,
      "learning_rate": 0.00015870820668693008,
      "loss": 25.9705,
      "step": 3150
    },
    {
      "epoch": 1.4479638009049773,
      "grad_norm": 15305.8046875,
      "learning_rate": 0.0001564285714285714,
      "loss": 26.648,
      "step": 3200
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 199244.65625,
      "learning_rate": 0.00015414893617021278,
      "loss": 25.8075,
      "step": 3250
    },
    {
      "epoch": 1.493212669683258,
      "grad_norm": 19984.30859375,
      "learning_rate": 0.0001518693009118541,
      "loss": 26.2987,
      "step": 3300
    },
    {
      "epoch": 1.5158371040723981,
      "grad_norm": 15389.333984375,
      "learning_rate": 0.00014958966565349543,
      "loss": 25.9101,
      "step": 3350
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 15945.36328125,
      "learning_rate": 0.00014731003039513676,
      "loss": 27.0753,
      "step": 3400
    },
    {
      "epoch": 1.5610859728506787,
      "grad_norm": 12285.9091796875,
      "learning_rate": 0.0001450303951367781,
      "loss": 27.8868,
      "step": 3450
    },
    {
      "epoch": 1.5837104072398192,
      "grad_norm": 14028.5888671875,
      "learning_rate": 0.00014275075987841944,
      "loss": 26.9824,
      "step": 3500
    },
    {
      "epoch": 1.5837104072398192,
      "eval_loss": 26.844064712524414,
      "eval_runtime": 15.2949,
      "eval_samples_per_second": 256.884,
      "eval_steps_per_second": 32.168,
      "step": 3500
    },
    {
      "epoch": 1.6063348416289593,
      "grad_norm": 18009.330078125,
      "learning_rate": 0.00014047112462006078,
      "loss": 25.9473,
      "step": 3550
    },
    {
      "epoch": 1.6289592760180995,
      "grad_norm": 14306.2421875,
      "learning_rate": 0.0001381914893617021,
      "loss": 26.0299,
      "step": 3600
    },
    {
      "epoch": 1.6515837104072397,
      "grad_norm": 19829.384765625,
      "learning_rate": 0.00013591185410334345,
      "loss": 25.8994,
      "step": 3650
    },
    {
      "epoch": 1.6742081447963801,
      "grad_norm": 15118.76953125,
      "learning_rate": 0.0001336322188449848,
      "loss": 26.5688,
      "step": 3700
    },
    {
      "epoch": 1.6968325791855203,
      "grad_norm": 53084.03515625,
      "learning_rate": 0.00013135258358662613,
      "loss": 26.7844,
      "step": 3750
    },
    {
      "epoch": 1.7194570135746607,
      "grad_norm": 61987.8203125,
      "learning_rate": 0.00012907294832826746,
      "loss": 27.3897,
      "step": 3800
    },
    {
      "epoch": 1.742081447963801,
      "grad_norm": 14815.41796875,
      "learning_rate": 0.0001267933130699088,
      "loss": 26.8442,
      "step": 3850
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 85908.015625,
      "learning_rate": 0.00012451367781155014,
      "loss": 26.0856,
      "step": 3900
    },
    {
      "epoch": 1.7873303167420813,
      "grad_norm": 69751.3671875,
      "learning_rate": 0.00012223404255319148,
      "loss": 26.1215,
      "step": 3950
    },
    {
      "epoch": 1.8099547511312217,
      "grad_norm": 16127.1591796875,
      "learning_rate": 0.00011995440729483283,
      "loss": 26.3645,
      "step": 4000
    },
    {
      "epoch": 1.8099547511312217,
      "eval_loss": 26.48813819885254,
      "eval_runtime": 15.4827,
      "eval_samples_per_second": 253.767,
      "eval_steps_per_second": 31.777,
      "step": 4000
    },
    {
      "epoch": 1.8325791855203621,
      "grad_norm": 25381.390625,
      "learning_rate": 0.00011767477203647415,
      "loss": 26.6247,
      "step": 4050
    },
    {
      "epoch": 1.8552036199095023,
      "grad_norm": 20673.46484375,
      "learning_rate": 0.00011539513677811549,
      "loss": 25.8075,
      "step": 4100
    },
    {
      "epoch": 1.8778280542986425,
      "grad_norm": 19937.318359375,
      "learning_rate": 0.00011311550151975683,
      "loss": 26.6663,
      "step": 4150
    },
    {
      "epoch": 1.9004524886877827,
      "grad_norm": 18550.537109375,
      "learning_rate": 0.00011083586626139818,
      "loss": 26.8959,
      "step": 4200
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 16495.2265625,
      "learning_rate": 0.00010855623100303951,
      "loss": 26.8062,
      "step": 4250
    },
    {
      "epoch": 1.9457013574660633,
      "grad_norm": 12073.951171875,
      "learning_rate": 0.00010627659574468084,
      "loss": 25.8878,
      "step": 4300
    },
    {
      "epoch": 1.9683257918552037,
      "grad_norm": 16144.529296875,
      "learning_rate": 0.00010399696048632218,
      "loss": 26.7939,
      "step": 4350
    },
    {
      "epoch": 1.990950226244344,
      "grad_norm": 24570.43359375,
      "learning_rate": 0.00010171732522796353,
      "loss": 26.7668,
      "step": 4400
    },
    {
      "epoch": 2.013574660633484,
      "grad_norm": 15530.7939453125,
      "learning_rate": 9.943768996960486e-05,
      "loss": 27.3213,
      "step": 4450
    },
    {
      "epoch": 2.0361990950226243,
      "grad_norm": 18589.392578125,
      "learning_rate": 9.715805471124619e-05,
      "loss": 26.6538,
      "step": 4500
    },
    {
      "epoch": 2.0361990950226243,
      "eval_loss": 26.782052993774414,
      "eval_runtime": 15.3494,
      "eval_samples_per_second": 255.971,
      "eval_steps_per_second": 32.053,
      "step": 4500
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 14326.3583984375,
      "learning_rate": 9.487841945288753e-05,
      "loss": 27.5511,
      "step": 4550
    },
    {
      "epoch": 2.081447963800905,
      "grad_norm": 15520.98046875,
      "learning_rate": 9.259878419452886e-05,
      "loss": 26.1227,
      "step": 4600
    },
    {
      "epoch": 2.1040723981900453,
      "grad_norm": 23126.064453125,
      "learning_rate": 9.031914893617021e-05,
      "loss": 26.5699,
      "step": 4650
    },
    {
      "epoch": 2.1266968325791855,
      "grad_norm": 18228.455078125,
      "learning_rate": 8.803951367781154e-05,
      "loss": 26.633,
      "step": 4700
    },
    {
      "epoch": 2.1493212669683257,
      "grad_norm": 14481.9306640625,
      "learning_rate": 8.575987841945288e-05,
      "loss": 27.3088,
      "step": 4750
    },
    {
      "epoch": 2.171945701357466,
      "grad_norm": 16060.0126953125,
      "learning_rate": 8.348024316109421e-05,
      "loss": 26.4047,
      "step": 4800
    },
    {
      "epoch": 2.1945701357466065,
      "grad_norm": 26226.58984375,
      "learning_rate": 8.120060790273556e-05,
      "loss": 26.1167,
      "step": 4850
    },
    {
      "epoch": 2.2171945701357467,
      "grad_norm": 14493.1640625,
      "learning_rate": 7.89209726443769e-05,
      "loss": 25.9256,
      "step": 4900
    },
    {
      "epoch": 2.239819004524887,
      "grad_norm": 30044.466796875,
      "learning_rate": 7.664133738601823e-05,
      "loss": 26.448,
      "step": 4950
    },
    {
      "epoch": 2.262443438914027,
      "grad_norm": 19315.82421875,
      "learning_rate": 7.436170212765956e-05,
      "loss": 26.9288,
      "step": 5000
    },
    {
      "epoch": 2.262443438914027,
      "eval_loss": 26.88685417175293,
      "eval_runtime": 15.2967,
      "eval_samples_per_second": 256.853,
      "eval_steps_per_second": 32.164,
      "step": 5000
    },
    {
      "epoch": 2.2850678733031673,
      "grad_norm": 13573.52734375,
      "learning_rate": 7.208206686930091e-05,
      "loss": 27.076,
      "step": 5050
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 18750.57421875,
      "learning_rate": 6.980243161094224e-05,
      "loss": 26.7695,
      "step": 5100
    },
    {
      "epoch": 2.330316742081448,
      "grad_norm": 17081.8984375,
      "learning_rate": 6.752279635258359e-05,
      "loss": 26.6064,
      "step": 5150
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 29492.279296875,
      "learning_rate": 6.524316109422491e-05,
      "loss": 25.489,
      "step": 5200
    },
    {
      "epoch": 2.3755656108597285,
      "grad_norm": 17738.72265625,
      "learning_rate": 6.296352583586626e-05,
      "loss": 26.4243,
      "step": 5250
    },
    {
      "epoch": 2.3981900452488687,
      "grad_norm": 16728.921875,
      "learning_rate": 6.068389057750759e-05,
      "loss": 26.5283,
      "step": 5300
    },
    {
      "epoch": 2.420814479638009,
      "grad_norm": 23612.736328125,
      "learning_rate": 5.840425531914893e-05,
      "loss": 25.2951,
      "step": 5350
    },
    {
      "epoch": 2.4434389140271495,
      "grad_norm": 15740.873046875,
      "learning_rate": 5.612462006079026e-05,
      "loss": 26.4166,
      "step": 5400
    },
    {
      "epoch": 2.4660633484162897,
      "grad_norm": 15180.373046875,
      "learning_rate": 5.384498480243161e-05,
      "loss": 25.9333,
      "step": 5450
    },
    {
      "epoch": 2.48868778280543,
      "grad_norm": 128767.1875,
      "learning_rate": 5.156534954407294e-05,
      "loss": 26.9426,
      "step": 5500
    },
    {
      "epoch": 2.48868778280543,
      "eval_loss": 26.783775329589844,
      "eval_runtime": 15.4208,
      "eval_samples_per_second": 254.786,
      "eval_steps_per_second": 31.905,
      "step": 5500
    },
    {
      "epoch": 2.51131221719457,
      "grad_norm": 990159.125,
      "learning_rate": 4.928571428571428e-05,
      "loss": 26.1602,
      "step": 5550
    },
    {
      "epoch": 2.5339366515837103,
      "grad_norm": 26027.94921875,
      "learning_rate": 4.700607902735562e-05,
      "loss": 26.2695,
      "step": 5600
    },
    {
      "epoch": 2.5565610859728505,
      "grad_norm": 23684.8203125,
      "learning_rate": 4.472644376899696e-05,
      "loss": 26.6963,
      "step": 5650
    },
    {
      "epoch": 2.579185520361991,
      "grad_norm": 16099.4267578125,
      "learning_rate": 4.2446808510638295e-05,
      "loss": 25.9572,
      "step": 5700
    },
    {
      "epoch": 2.6018099547511313,
      "grad_norm": 22784.91015625,
      "learning_rate": 4.016717325227963e-05,
      "loss": 26.7944,
      "step": 5750
    },
    {
      "epoch": 2.6244343891402715,
      "grad_norm": 21936.6328125,
      "learning_rate": 3.788753799392097e-05,
      "loss": 25.8469,
      "step": 5800
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 12835.220703125,
      "learning_rate": 3.560790273556231e-05,
      "loss": 27.0862,
      "step": 5850
    },
    {
      "epoch": 2.669683257918552,
      "grad_norm": 15356.3408203125,
      "learning_rate": 3.3328267477203645e-05,
      "loss": 26.4128,
      "step": 5900
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 17379.341796875,
      "learning_rate": 3.104863221884498e-05,
      "loss": 25.8423,
      "step": 5950
    },
    {
      "epoch": 2.7149321266968327,
      "grad_norm": 20903.240234375,
      "learning_rate": 2.876899696048632e-05,
      "loss": 26.1727,
      "step": 6000
    },
    {
      "epoch": 2.7149321266968327,
      "eval_loss": 26.577219009399414,
      "eval_runtime": 15.3065,
      "eval_samples_per_second": 256.689,
      "eval_steps_per_second": 32.143,
      "step": 6000
    },
    {
      "epoch": 2.737556561085973,
      "grad_norm": 15966.8271484375,
      "learning_rate": 2.6489361702127657e-05,
      "loss": 26.9613,
      "step": 6050
    },
    {
      "epoch": 2.760180995475113,
      "grad_norm": 18800.802734375,
      "learning_rate": 2.4209726443768995e-05,
      "loss": 26.9915,
      "step": 6100
    },
    {
      "epoch": 2.7828054298642533,
      "grad_norm": 17464.681640625,
      "learning_rate": 2.1930091185410332e-05,
      "loss": 26.3164,
      "step": 6150
    },
    {
      "epoch": 2.8054298642533935,
      "grad_norm": 19105.693359375,
      "learning_rate": 1.965045592705167e-05,
      "loss": 26.7248,
      "step": 6200
    },
    {
      "epoch": 2.8280542986425337,
      "grad_norm": 16104.330078125,
      "learning_rate": 1.7370820668693007e-05,
      "loss": 26.6172,
      "step": 6250
    },
    {
      "epoch": 2.8506787330316743,
      "grad_norm": 25252.123046875,
      "learning_rate": 1.5091185410334345e-05,
      "loss": 26.0765,
      "step": 6300
    },
    {
      "epoch": 2.8733031674208145,
      "grad_norm": 16024.619140625,
      "learning_rate": 1.2811550151975684e-05,
      "loss": 26.7874,
      "step": 6350
    },
    {
      "epoch": 2.8959276018099547,
      "grad_norm": 19965.4765625,
      "learning_rate": 1.0531914893617022e-05,
      "loss": 27.0215,
      "step": 6400
    },
    {
      "epoch": 2.918552036199095,
      "grad_norm": 18135.728515625,
      "learning_rate": 8.252279635258357e-06,
      "loss": 26.4312,
      "step": 6450
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 18406.66015625,
      "learning_rate": 5.972644376899696e-06,
      "loss": 26.2389,
      "step": 6500
    },
    {
      "epoch": 2.9411764705882355,
      "eval_loss": 26.720399856567383,
      "eval_runtime": 15.2942,
      "eval_samples_per_second": 256.894,
      "eval_steps_per_second": 32.169,
      "step": 6500
    },
    {
      "epoch": 2.9638009049773757,
      "grad_norm": 22228.630859375,
      "learning_rate": 3.6930091185410333e-06,
      "loss": 26.0939,
      "step": 6550
    },
    {
      "epoch": 2.986425339366516,
      "grad_norm": 15237.3603515625,
      "learning_rate": 1.4133738601823706e-06,
      "loss": 27.1352,
      "step": 6600
    }
  ],
  "logging_steps": 50,
  "max_steps": 6630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2623150751219712.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
